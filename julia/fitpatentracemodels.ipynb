{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook shows how to obtain the basic results from Hunter et al. (2021)\n",
    "# (corresponding to figs 3,4 & 5 / supp tables 2, 3, 6, 7, 8 & 9)\n",
    "# it is reimplemented from the original paper:\n",
    "# it uses a newer version of the EM model fitting code with a different M step\n",
    "# (& a newer version of julia etc)\n",
    "# and substitutes Julia equivalents for Matlab analyses\n",
    "#\n",
    "# so it does not precisely match results numerically but reproduces the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some required packages\n",
    "# ( you need to install these eg via import Pkg; Pkg.add(...) )\n",
    "\n",
    "using CSV\n",
    "using DataFrames\n",
    "using LinearAlgebra\n",
    "using SpecialFunctions:erf\n",
    "using StatsFuns:logsumexp\n",
    "using GLM\n",
    "using Statistics\n",
    "using StatsBase\n",
    "using MixedModels\n",
    "using CategoricalArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the EM model fitting code \n",
    "# get this from https://github.com/ndawlab/em\n",
    "\n",
    "directory = \"/home/daw/winhome/Dropbox/expts/julia em/git/em\"\n",
    "\n",
    "push!(LOAD_PATH,directory)\n",
    "using EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch in the python optimization function to produce results more similar to the original code\n",
    "# (note you have to run this with only one thread / \"unset JULIA_NUM_THREADS\" ignoring warning)\n",
    "# you can also skip this, & run julia multithreaded with the native optimizer to get (slightly\n",
    "# different) results faster ;-)\n",
    "\n",
    "using PyCall\n",
    "using ForwardDiff\n",
    "\n",
    "so = pyimport(\"scipy.optimize\")\n",
    "\n",
    "function EM.optimizesubject(likfun, startx)\n",
    "    # call python's optimization function which used to work a little better than julia's\n",
    "\t# but is not thread safe\n",
    "\ta = so.minimize(likfun, startx, method=\"L-BFGS-B\", jac = (x->ForwardDiff.gradient(likfun,x)))\n",
    "\t#println(a[\"message\"])\n",
    "\n",
    "\treturn((a[\"fun\"],a[\"x\"])::Tuple{Float64,Array{Float64,1}})\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#3 (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model code (likelihood function)\n",
    "\n",
    "include(\"patent likfuns.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "743"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data \n",
    "\n",
    "alldata = CSV.File(\"patent_investments_743subs.csv\") |> DataFrame\n",
    "exp1subs = unique(alldata.sub)[1:412]\n",
    "exp1NS = length(exp1subs)\n",
    "\n",
    "exp2subs = unique(alldata.sub)[413:end]\n",
    "exp2NS = length(exp2subs)\n",
    "\n",
    "allsubs = unique(alldata.sub)\n",
    "allNS = length(allsubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the covariates\n",
    "# make sure the covariates are z scored separately within cohorts\n",
    "\n",
    "mergedcovars = CSV.File(\"mergedcovars.csv\") |> DataFrame \n",
    "exp1covars = mergedcovars[1:412,:]\n",
    "exp1covars.iqZ = zscore(exp1covars.iqZ)\n",
    "exp1covars.lsasZ = zscore(exp1covars.lsasZ)\n",
    "\n",
    "exp2covars = mergedcovars[413:end,:]\n",
    "exp2covars.iqZ = zscore(exp2covars.iqZ)\n",
    "exp2covars.lsasZ = zscore(exp2covars.lsasZ);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter: 667\n",
      "betas: [1.23 1.2 -0.95 0.01 -0.34 -0.11 0.08 0.13]\n",
      "sigma: [0.23, 0.61, 0.8, 0.01, 0.03, 0.02, 0.01, 0.01]\n",
      "free energy: -31978.482325\n",
      "change: [3.0e-6, 1.0e-6, -4.0e-6, 6.1e-5, -3.0e-6, -1.2e-5, 2.5e-5, 1.6e-5, 1.2e-5, 2.0e-6, 1.0e-6, 0.001, 0.000682, 4.7e-5, 0.000547, 0.000658]\n",
      "max: 0.001\n"
     ]
    }
   ],
   "source": [
    "# Expt 1, basic model\n",
    "# set up design matrix for fit\n",
    "\n",
    "X = ones(exp1NS)\n",
    "\n",
    "# start points\n",
    "\n",
    "betas = [-1. 0 0 0 0 0 0 0 ]\n",
    "sigma = [10.,1,1,1,1,1,1,1]\n",
    "\n",
    "# fit the model\n",
    "\n",
    "(betas,sigma,x,l,h) = em(alldata,exp1subs,X,betas,sigma,ewalik; emtol=1e-3, full=false, maxiter=1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "beta ~ 1 + lsasZ + iqZ\n",
       "\n",
       "Coefficients:\n",
       "──────────────────────────────────────────────────────────────────────────────\n",
       "                  Coef.  Std. Error      t  Pr(>|t|)    Lower 95%    Upper 95%\n",
       "──────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)   1.23171      0.021374  57.63    <1e-99   1.18969      1.27372\n",
       "lsasZ        -0.045646     0.021404  -2.13    0.0336  -0.0877215   -0.00357045\n",
       "iqZ           0.0366528    0.021404   1.71    0.0876  -0.00542279   0.0787283\n",
       "──────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "alpha ~ 1 + lsasZ + iqZ\n",
       "\n",
       "Coefficients:\n",
       "──────────────────────────────────────────────────────────────────────────────\n",
       "                   Coef.  Std. Error      t  Pr(>|t|)    Lower 95%   Upper 95%\n",
       "──────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)   0.164033    0.00842711  19.46    <1e-59   0.147467    0.180599\n",
       "lsasZ        -0.00789078  0.00843893  -0.94    0.3503  -0.0244799   0.00869832\n",
       "iqZ           0.0110433   0.00843893   1.31    0.1914  -0.00554582  0.0276324\n",
       "──────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "w ~ 1 + lsasZ + iqZ\n",
       "\n",
       "Coefficients:\n",
       "──────────────────────────────────────────────────────────────────────────\n",
       "                 Coef.  Std. Error      t  Pr(>|t|)   Lower 95%  Upper 95%\n",
       "──────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)  0.217108   0.00952002  22.81    <1e-74  0.198394    0.235822\n",
       "lsasZ        0.0224051  0.00953338   2.35    0.0192  0.00366457  0.0411456\n",
       "iqZ          0.0224284  0.00953338   2.35    0.0191  0.00368782  0.0411689\n",
       "──────────────────────────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x gives the per subject parameters (some need transforming to 0-1)\n",
    "# extract them and regress on the covariates (originally we saved these and did regressions in Matlab)\n",
    "# note significant effect of LSAS on w\n",
    "\n",
    "exp1covars.beta = x[:,1]\n",
    "exp1covars.alpha = 1 .- ( 0.5 .+ 0.5 .* erf.(x[:,2] ./ sqrt(2))) # alpha = 1-phi, squashed\n",
    "exp1covars.w = ( 0.5 .+ 0.5 .* erf.(x[:,3] ./ sqrt(2)))\n",
    "\n",
    "display(lm(@formula(beta~lsasZ+iqZ),exp1covars))\n",
    "display(lm(@formula(alpha~lsasZ+iqZ),exp1covars))\n",
    "display(lm(@formula(w~lsasZ+iqZ),exp1covars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter: 687\n",
      "betas: [1.28 1.29 -0.64 -1.46 0.02 -0.34 -0.1 0.08 0.13]\n",
      "sigma: [0.24, 0.65, 0.87, 1.28, 0.0, 0.03, 0.02, 0.01, 0.0]\n",
      "free energy: -31737.069446\n",
      "change: [3.0e-6, 5.0e-6, -8.0e-6, -5.0e-6, 6.8e-5, -5.0e-6, -1.6e-5, 3.1e-5, 1.9e-5, 3.4e-5, 9.9e-5, 3.5e-5, 1.4e-5, 0.000999, 0.000666, 0.00015, 0.000474, 0.000638]\n",
      "max: 0.000999\n"
     ]
    }
   ],
   "source": [
    "# Repeat the process with the valenced model, expt 1\n",
    "\n",
    "# set up the design matrix\n",
    "\n",
    "X = ones(exp1NS)\n",
    "\n",
    "# start points \n",
    "\n",
    "betas = [-1. 0 0 0 0 0 0 0 0]\n",
    "sigma = [10.,1,1,1,1,1,1,1,1]\n",
    "\n",
    "# fit the model\n",
    "\n",
    "(betas,sigma,x,l,h) = em(alldata,exp1subs,X,betas,sigma,ewalik_valenced; emtol=1e-3, full=false, maxiter=1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "betavalenced ~ 1 + lsasZ + iqZ\n",
       "\n",
       "Coefficients:\n",
       "─────────────────────────────────────────────────────────────────────────────\n",
       "                  Coef.  Std. Error      t  Pr(>|t|)    Lower 95%   Upper 95%\n",
       "─────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)   1.27565     0.0214658  59.43    <1e-99   1.23345     1.31784\n",
       "lsasZ        -0.0395683   0.0214959  -1.84    0.0664  -0.0818245   0.00268797\n",
       "iqZ           0.0341687   0.0214959   1.59    0.1127  -0.00808758  0.0764249\n",
       "─────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "alphavalenced ~ 1 + lsasZ + iqZ\n",
       "\n",
       "Coefficients:\n",
       "──────────────────────────────────────────────────────────────────────────────\n",
       "                   Coef.  Std. Error      t  Pr(>|t|)    Lower 95%   Upper 95%\n",
       "──────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)   0.150189    0.0082747   18.15    <1e-53   0.133923    0.166456\n",
       "lsasZ        -0.00716423  0.00828631  -0.86    0.3878  -0.0234533   0.00912483\n",
       "iqZ           0.00970181  0.00828631   1.17    0.2424  -0.00658726  0.0259909\n",
       "──────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "wplus ~ 1 + lsasZ + iqZ\n",
       "\n",
       "Coefficients:\n",
       "──────────────────────────────────────────────────────────────────────────\n",
       "                 Coef.  Std. Error      t  Pr(>|t|)   Lower 95%  Upper 95%\n",
       "──────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)  0.305973    0.0112457  27.21    <1e-93  0.283866    0.328079\n",
       "lsasZ        0.0268589   0.0112615   2.39    0.0175  0.00472131  0.0489964\n",
       "iqZ          0.0359981   0.0112615   3.20    0.0015  0.0138606   0.0581357\n",
       "──────────────────────────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "wminus ~ 1 + lsasZ + iqZ\n",
       "\n",
       "Coefficients:\n",
       "────────────────────────────────────────────────────────────────────────────\n",
       "                   Coef.  Std. Error      t  Pr(>|t|)   Lower 95%  Upper 95%\n",
       "────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)   0.115345    0.00855081  13.49    <1e-33   0.0985359  0.132154\n",
       "lsasZ         0.00607647  0.00856281   0.71    0.4783  -0.0107561  0.0229091\n",
       "iqZ          -0.00128756  0.00856281  -0.15    0.8805  -0.0181202  0.0155451\n",
       "────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x gives the per subject parameters (some need transforming to 0-1)\n",
    "# extract them and regress on the covariates (originally we saved these and did regressions in Matlab)\n",
    "# note significant effect of LSAS on wplus, not wminus\n",
    "\n",
    "exp1covars.betavalenced = x[:,1]\n",
    "exp1covars.alphavalenced = 1 .- ( 0.5 .+ 0.5 .* erf.(x[:,2] ./ sqrt(2))) # alpha = 1-phi, squashed\n",
    "exp1covars.wplus = ( 0.5 .+ 0.5 .* erf.(x[:,3] ./ sqrt(2)))\n",
    "exp1covars.wminus = ( 0.5 .+ 0.5 .* erf.(x[:,4] ./ sqrt(2)))\n",
    "\n",
    "display(lm(@formula(betavalenced~lsasZ+iqZ),exp1covars))\n",
    "display(lm(@formula(alphavalenced~lsasZ+iqZ),exp1covars))\n",
    "display(lm(@formula(wplus~lsasZ+iqZ),exp1covars)) \n",
    "display(lm(@formula(wminus~lsasZ+iqZ),exp1covars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{tabular}\n",
       "{l | r | r | r | r | r}\n",
       " & Est. & SE & z & p & $\\sigma_\\text{sub}$ \\\\\n",
       "\\hline\n",
       "(Intercept) & 0.1149 & 0.0085 & 13.52 & <1e-40 & 0.1637 \\\\\n",
       "valence & 0.1911 & 0.0140 & 13.60 & <1e-41 & 0.2773 \\\\\n",
       "lsasZ & 0.0054 & 0.0088 & 0.62 & 0.5385 & 0.0378 \\\\\n",
       "iqZ & -0.0010 & 0.0081 & -0.13 & 0.8994 & 0.0111 \\\\\n",
       "valence \\& lsasZ & 0.0238 & 0.0143 & 1.67 & 0.0957 & 0.0350 \\\\\n",
       "valence \\& iqZ & 0.0372 & 0.0135 & 2.76 & 0.0057 & 0.0144 \\\\\n",
       "Residual & 0.0393 &  &  &  &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "|                 |    Est. |     SE |     z |      p |  σ_sub |\n",
       "|:--------------- | -------:| ------:| -----:| ------:| ------:|\n",
       "| (Intercept)     |  0.1149 | 0.0085 | 13.52 | <1e-40 | 0.1637 |\n",
       "| valence         |  0.1911 | 0.0140 | 13.60 | <1e-41 | 0.2773 |\n",
       "| lsasZ           |  0.0054 | 0.0088 |  0.62 | 0.5385 | 0.0378 |\n",
       "| iqZ             | -0.0010 | 0.0081 | -0.13 | 0.8994 | 0.0111 |\n",
       "| valence & lsasZ |  0.0238 | 0.0143 |  1.67 | 0.0957 | 0.0350 |\n",
       "| valence & iqZ   |  0.0372 | 0.0135 |  2.76 | 0.0057 | 0.0144 |\n",
       "| Residual        |  0.0393 |        |       |        |        |\n"
      ],
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       " w ~ 1 + valence + lsasZ + iqZ + valence & lsasZ + valence & iqZ + (1 + valence + lsasZ + iqZ + valence & lsasZ + valence & iqZ | sub)\n",
       "   logLik   -2 logLik     AIC       AICc        BIC    \n",
       "   170.8632  -341.7263  -285.7263  -283.6836  -153.7296\n",
       "\n",
       "Variance components:\n",
       "              Column      Variance  Std.Dev.   Corr.\n",
       "sub      (Intercept)      0.0267827 0.1636542\n",
       "         valence          0.0768738 0.2772613 -0.60\n",
       "         lsasZ            0.0014266 0.0377704 +0.07 +0.07\n",
       "         iqZ              0.0001224 0.0110613 +0.93 -0.26 +0.09\n",
       "         valence & lsasZ  0.0012271 0.0350306 -0.08 +0.29 -0.90 +0.06\n",
       "         valence & iqZ    0.0002060 0.0143515 -0.32 +0.95 +0.21 +0.05 +0.21\n",
       "Residual                  0.0015420 0.0392688\n",
       " Number of obs: 824; levels of grouping factors: 412\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "─────────────────────────────────────────────────────────\n",
       "                       Coef.  Std. Error      z  Pr(>|z|)\n",
       "─────────────────────────────────────────────────────────\n",
       "(Intercept)       0.114921    0.00850228  13.52    <1e-40\n",
       "valence           0.191104    0.0140498   13.60    <1e-41\n",
       "lsasZ             0.00539866  0.0087761    0.62    0.5385\n",
       "iqZ              -0.00101921  0.00806303  -0.13    0.8994\n",
       "valence & lsasZ   0.0238161   0.0142932    1.67    0.0957\n",
       "valence & iqZ     0.0372287   0.0134664    2.76    0.0057\n",
       "─────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# supp table 7: compare w+ to w- (interaction with lsas is only trending in Exp 1)\n",
    "# using mixed model to capture repeated measures by subject\n",
    "# note that Julia's MixedModels, unlike Matlab, doesnt use Satterthwaite DOF\n",
    "# but this difference is minimal for this many subjects\n",
    "\n",
    "exp1ws = DataFrame(w = [exp1covars.wplus;exp1covars.wminus], \n",
    "    sub = categorical([exp1subs;exp1subs]), \n",
    "    iqZ = [exp1covars.iqZ; exp1covars.iqZ], \n",
    "    lsasZ = [exp1covars.lsasZ; exp1covars.lsasZ], \n",
    "    valence = [ones(size(exp1subs));zeros(size(exp1subs))])\n",
    "\n",
    "mm = (fit(MixedModel, @formula(w ~ 1 + valence * (lsasZ + iqZ) + (1 + valence * (lsasZ + iqZ) |sub)), exp1ws))\n",
    "\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter: 910\n",
      "betas: [1.13 1.24 -1.08 -0.05 -0.26 -0.17 0.09 0.15]\n",
      "sigma: [0.43, 0.68, 1.26, 0.01, 0.01, 0.0, 0.02, 0.01]\n",
      "free energy: -27648.934518\n",
      "change: [1.0e-6, 0.0, -1.0e-6, -0.000121, -2.4e-5, -4.1e-5, 6.7e-5, 3.7e-5, 3.0e-6, 1.0e-6, 1.0e-6, 0.000174, 0.000999, 0.00096, 7.8e-5, 0.000398]\n",
      "max: 0.000999\n"
     ]
    }
   ],
   "source": [
    "# Expt 2, basic model\n",
    "# set up design matrix for fit\n",
    "\n",
    "X = ones(exp2NS)\n",
    "\n",
    "# initial conditions\n",
    "\n",
    "betas = [-1. 0 0 0 0 0 0 0 ]\n",
    "sigma = [10.,1,1,1,1,1,1,1]\n",
    "\n",
    "# fit the model\n",
    "\n",
    "(betas,sigma,x,l,h) = em(alldata,exp2subs,X,betas,sigma,ewalik; emtol=1e-3, full=false, maxiter=1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "beta ~ 1 + lsasZ + iqZ\n",
       "\n",
       "Coefficients:\n",
       "────────────────────────────────────────────────────────────────────────────\n",
       "                   Coef.  Std. Error      t  Pr(>|t|)   Lower 95%  Upper 95%\n",
       "────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)   1.13069      0.0333753  33.88    <1e-99   1.06503    1.19634\n",
       "lsasZ        -0.00173645   0.033437   -0.05    0.9586  -0.0675145  0.0640416\n",
       "iqZ           0.115738     0.033437    3.46    0.0006   0.0499601  0.181516\n",
       "────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "alpha ~ 1 + lsasZ + iqZ\n",
       "\n",
       "Coefficients:\n",
       "───────────────────────────────────────────────────────────────────────────\n",
       "                 Coef.  Std. Error      t  Pr(>|t|)    Lower 95%  Upper 95%\n",
       "───────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)  0.161999   0.00943595  17.17    <1e-46   0.143436    0.180561\n",
       "lsasZ        0.0156189  0.0094534    1.65    0.0995  -0.00297803  0.0342159\n",
       "iqZ          0.010175   0.0094534    1.08    0.2826  -0.00842193  0.028772\n",
       "───────────────────────────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "w ~ 1 + lsasZ + iqZ\n",
       "\n",
       "Coefficients:\n",
       "────────────────────────────────────────────────────────────────────────────\n",
       "                  Coef.  Std. Error      t  Pr(>|t|)    Lower 95%  Upper 95%\n",
       "────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)  0.204007     0.0130319  15.65    <1e-40   0.17837     0.229643\n",
       "lsasZ        0.033322     0.013056    2.55    0.0112   0.00763802  0.059006\n",
       "iqZ          0.00364774   0.013056    0.28    0.7801  -0.0220363   0.0293317\n",
       "────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x gives the per subject parameters (some need transforming to 0-1)\n",
    "# extract them and regresss on the covariates (originally we saved these and did regressions in Matlab)\n",
    "# note significant effect of LSAS on w\n",
    "\n",
    "exp2covars.beta = x[:,1]\n",
    "exp2covars.alpha = 1 .- ( 0.5 .+ 0.5 .* erf.(x[:,2] ./ sqrt(2))) # alpha = 1-phi, squashed\n",
    "exp2covars.w = ( 0.5 .+ 0.5 .* erf.(x[:,3] ./ sqrt(2)))\n",
    "\n",
    "display(lm(@formula(beta~lsasZ+iqZ),exp2covars))\n",
    "display(lm(@formula(alpha~lsasZ+iqZ),exp2covars))\n",
    "display(lm(@formula(w~lsasZ+iqZ),exp2covars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter: 722\n",
      "betas: [1.19 1.29 -0.87 -1.25 -0.04 -0.27 -0.17 0.11 0.16]\n",
      "sigma: [0.34, 0.68, 1.11, 1.27, 0.01, 0.01, 0.01, 0.01, 0.01]\n",
      "free energy: -27433.19149\n",
      "change: [3.0e-6, 1.0e-6, -3.0e-6, -6.0e-6, -6.8e-5, -1.7e-5, -2.6e-5, 2.3e-5, 1.4e-5, 1.0e-5, 2.0e-6, 1.0e-6, 3.0e-6, 0.000545, 0.001, 0.000912, 0.000317, 0.000446]\n",
      "max: 0.001\n"
     ]
    }
   ],
   "source": [
    "# Repeat the process with the valenced model, expt 2\n",
    "\n",
    "# set up the design matrix\n",
    "\n",
    "X = ones(exp2NS)\n",
    "\n",
    "betas = [-1. 0 0 0 0 0 0 0 0]\n",
    "sigma = [10.,1,1,1,1,1,1,1,1]\n",
    "\n",
    "(betas,sigma,x,l,h) = em(alldata,exp2subs,X,betas,sigma,ewalik_valenced; emtol=1e-3, full=false, maxiter=1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "betavalenced ~ 1 + lsasZ + iqZ\n",
       "\n",
       "Coefficients:\n",
       "───────────────────────────────────────────────────────────────────────────\n",
       "                  Coef.  Std. Error      t  Pr(>|t|)   Lower 95%  Upper 95%\n",
       "───────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)   1.19397     0.0293161  40.73    <1e-99   1.1363     1.25164\n",
       "lsasZ        -0.0149815   0.0293703  -0.51    0.6103  -0.0727595  0.0427964\n",
       "iqZ           0.117881    0.0293703   4.01    <1e-04   0.0601027  0.175659\n",
       "───────────────────────────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "alphavalenced ~ 1 + lsasZ + iqZ\n",
       "\n",
       "Coefficients:\n",
       "────────────────────────────────────────────────────────────────────────────\n",
       "                  Coef.  Std. Error      t  Pr(>|t|)    Lower 95%  Upper 95%\n",
       "────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)  0.152579    0.0093286   16.36    <1e-43   0.134228    0.17093\n",
       "lsasZ        0.0128441   0.00934585   1.37    0.1703  -0.00554129  0.0312295\n",
       "iqZ          0.00776495  0.00934585   0.83    0.4067  -0.0106204   0.0261503\n",
       "────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "wplus ~ 1 + lsasZ + iqZ\n",
       "\n",
       "Coefficients:\n",
       "──────────────────────────────────────────────────────────────────────────\n",
       "                 Coef.  Std. Error      t  Pr(>|t|)   Lower 95%  Upper 95%\n",
       "──────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)  0.255576    0.0134084  19.06    <1e-54   0.229199   0.281953\n",
       "lsasZ        0.0462295   0.0134332   3.44    0.0007   0.0198035  0.0726555\n",
       "iqZ          0.0082411   0.0134332   0.61    0.5400  -0.0181849  0.0346671\n",
       "──────────────────────────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "wminus ~ 1 + lsasZ + iqZ\n",
       "\n",
       "Coefficients:\n",
       "────────────────────────────────────────────────────────────────────────────\n",
       "                   Coef.  Std. Error      t  Pr(>|t|)   Lower 95%  Upper 95%\n",
       "────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)   0.156699     0.0112417  13.94    <1e-34   0.134584   0.178814\n",
       "lsasZ         0.00740131   0.0112625   0.66    0.5115  -0.0147546  0.0295572\n",
       "iqZ          -0.0180707    0.0112625  -1.60    0.1096  -0.0402266  0.0040852\n",
       "────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "betavalenced ~ 1 + f1 + f2 + f3 + iqZ\n",
       "\n",
       "Coefficients:\n",
       "───────────────────────────────────────────────────────────────────────────\n",
       "                  Coef.  Std. Error      t  Pr(>|t|)   Lower 95%  Upper 95%\n",
       "───────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)   1.19397     0.0293431  40.69    <1e-99   1.13624    1.2517\n",
       "f1           -0.0261703   0.0325765  -0.80    0.4224  -0.0902571  0.0379165\n",
       "f2            0.0200568   0.0298137   0.67    0.5016  -0.0385948  0.0787084\n",
       "f3           -0.0160888   0.0327853  -0.49    0.6239  -0.0805862  0.0484087\n",
       "iqZ           0.117773    0.0293975   4.01    <1e-04   0.0599404  0.175606\n",
       "───────────────────────────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "alphavalenced ~ 1 + f1 + f2 + f3 + iqZ\n",
       "\n",
       "Coefficients:\n",
       "────────────────────────────────────────────────────────────────────────────\n",
       "                  Coef.  Std. Error      t  Pr(>|t|)    Lower 95%  Upper 95%\n",
       "────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)  0.152579    0.0093271   16.36    <1e-43   0.13423     0.170928\n",
       "f1           0.0108461   0.0103549    1.05    0.2957  -0.00952475  0.0312169\n",
       "f2           0.00168876  0.00947669   0.18    0.8587  -0.0169544   0.0203319\n",
       "f3           0.00762334  0.0104212    0.73    0.4650  -0.012878    0.0281247\n",
       "iqZ          0.00808648  0.00934437   0.87    0.3875  -0.0102964   0.0264694\n",
       "────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "wplus ~ 1 + f1 + f2 + f3 + iqZ\n",
       "\n",
       "Coefficients:\n",
       "─────────────────────────────────────────────────────────────────────────────\n",
       "                    Coef.  Std. Error      t  Pr(>|t|)   Lower 95%  Upper 95%\n",
       "─────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)   0.255576      0.0134327  19.03    <1e-54   0.22915    0.282002\n",
       "f1           -0.00698578    0.0149129  -0.47    0.6398  -0.0363235  0.0223519\n",
       "f2           -0.000323906   0.0136482  -0.02    0.9811  -0.0271735  0.0265257\n",
       "f3            0.0485017     0.0150085   3.23    0.0014   0.018976   0.0780274\n",
       "iqZ           0.00860215    0.0134576   0.64    0.5231  -0.0178725  0.0350769\n",
       "─────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "wminus ~ 1 + f1 + f2 + f3 + iqZ\n",
       "\n",
       "Coefficients:\n",
       "──────────────────────────────────────────────────────────────────────────────\n",
       "                    Coef.  Std. Error      t  Pr(>|t|)   Lower 95%   Upper 95%\n",
       "──────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)   0.156699      0.0112645  13.91    <1e-34   0.134539   0.178859\n",
       "f1            0.000429567   0.0125058   0.03    0.9726  -0.0241726  0.0250317\n",
       "f2            0.00593095    0.0114451   0.52    0.6047  -0.0165847  0.0284466\n",
       "f3            0.00749647    0.0125859   0.60    0.5518  -0.0172633  0.0322563\n",
       "iqZ          -0.0179236     0.0112853  -1.59    0.1132  -0.0401249  0.00427765\n",
       "──────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x gives the per subject parameters (some need transforming to 0-1)\n",
    "# extract them and regresss on the covariates (originally we saved these and did regressions in Matlab)\n",
    "# note significant effect of LSAS on wplus not wminus\n",
    "\n",
    "exp2covars.betavalenced = x[:,1]\n",
    "exp2covars.alphavalenced = 1 .- ( 0.5 .+ 0.5 .* erf.(x[:,2] ./ sqrt(2))) # alpha = 1-phi, squashed\n",
    "exp2covars.wplus = ( 0.5 .+ 0.5 .* erf.(x[:,3] ./ sqrt(2)))\n",
    "exp2covars.wminus = ( 0.5 .+ 0.5 .* erf.(x[:,4] ./ sqrt(2)))\n",
    "\n",
    "display(lm(@formula(betavalenced~lsasZ+iqZ),exp2covars))\n",
    "display(lm(@formula(alphavalenced~lsasZ+iqZ),exp2covars))\n",
    "display(lm(@formula(wplus~lsasZ+iqZ),exp2covars))\n",
    "display(lm(@formula(wminus~lsasZ+iqZ),exp2covars))\n",
    "\n",
    "# also regress on additional psychiatric symptom factors.\n",
    "# f3 is the one measuring social anxiety (significant against wplus not wminus)\n",
    "# f1 & f2 control for other symptom dimensions (not signif)\n",
    "\n",
    "display(lm(@formula(betavalenced~f1+f2+f3+iqZ),exp2covars))\n",
    "display(lm(@formula(alphavalenced~f1+f2+f3+iqZ),exp2covars))\n",
    "display(lm(@formula(wplus~f1+f2+f3+iqZ),exp2covars))\n",
    "display(lm(@formula(wminus~f1+f2+f3+iqZ),exp2covars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{tabular}\n",
       "{l | r | r | r | r | r}\n",
       " & Est. & SE & z & p & $\\sigma_\\text{sub}$ \\\\\n",
       "\\hline\n",
       "(Intercept) & 0.1569 & 0.0112 & 14.02 & <1e-43 & 0.1612 \\\\\n",
       "valence & 0.0963 & 0.0167 & 5.78 & <1e-08 & 0.2299 \\\\\n",
       "lsasZ & 0.0073 & 0.0114 & 0.65 & 0.5187 & 0.0268 \\\\\n",
       "iqZ & -0.0181 & 0.0120 & -1.51 & 0.1310 & 0.0316 \\\\\n",
       "valence \\& lsasZ & 0.0410 & 0.0169 & 2.43 & 0.0151 & 0.0293 \\\\\n",
       "valence \\& iqZ & 0.0324 & 0.0190 & 1.71 & 0.0877 & 0.1139 \\\\\n",
       "Residual & 0.1178 &  &  &  &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "|                 |    Est. |     SE |     z |      p |  σ_sub |\n",
       "|:--------------- | -------:| ------:| -----:| ------:| ------:|\n",
       "| (Intercept)     |  0.1569 | 0.0112 | 14.02 | <1e-43 | 0.1612 |\n",
       "| valence         |  0.0963 | 0.0167 |  5.78 | <1e-08 | 0.2299 |\n",
       "| lsasZ           |  0.0073 | 0.0114 |  0.65 | 0.5187 | 0.0268 |\n",
       "| iqZ             | -0.0181 | 0.0120 | -1.51 | 0.1310 | 0.0316 |\n",
       "| valence & lsasZ |  0.0410 | 0.0169 |  2.43 | 0.0151 | 0.0293 |\n",
       "| valence & iqZ   |  0.0324 | 0.0190 |  1.71 | 0.0877 | 0.1139 |\n",
       "| Residual        |  0.1178 |        |       |        |        |\n"
      ],
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       " w ~ 1 + valence + lsasZ + iqZ + valence & lsasZ + valence & iqZ + (1 + valence + lsasZ + iqZ + valence & lsasZ + valence & iqZ | sub)\n",
       "   logLik   -2 logLik     AIC       AICc        BIC    \n",
       "    63.3872  -126.7744   -70.7744   -68.2088    55.0931\n",
       "\n",
       "Variance components:\n",
       "              Column      Variance  Std.Dev.   Corr.\n",
       "sub      (Intercept)      0.0259970 0.1612359\n",
       "         valence          0.0528335 0.2298553 -0.61\n",
       "         lsasZ            0.0007167 0.0267707 +0.35 -0.19\n",
       "         iqZ              0.0009998 0.0316198 -0.38 +0.14 +0.16\n",
       "         valence & lsasZ  0.0008608 0.0293399 +0.08 +0.06 +0.86 +0.61\n",
       "         valence & iqZ    0.0129809 0.1139339 -0.04 +0.03 +0.09 -0.80 -0.34\n",
       "Residual                  0.0138772 0.1178014\n",
       " Number of obs: 662; levels of grouping factors: 331\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "─────────────────────────────────────────────────────────\n",
       "                       Coef.  Std. Error      z  Pr(>|z|)\n",
       "─────────────────────────────────────────────────────────\n",
       "(Intercept)       0.156886     0.0111866  14.02    <1e-43\n",
       "valence           0.096289     0.0166622   5.78    <1e-08\n",
       "lsasZ             0.00732602   0.0113521   0.65    0.5187\n",
       "iqZ              -0.0180821    0.0119733  -1.51    0.1310\n",
       "valence & lsasZ   0.0410086    0.0168795   2.43    0.0151\n",
       "valence & iqZ     0.0323787    0.0189591   1.71    0.0877\n",
       "─────────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "\\begin{tabular}\n",
       "{l | r | r | r | r | r}\n",
       " & Est. & SE & z & p & $\\sigma_\\text{sub}$ \\\\\n",
       "\\hline\n",
       "(Intercept) & 0.1304 & 0.0091 & 14.36 & <1e-46 & 0.1091 \\\\\n",
       "valence & 0.1058 & 0.0160 & 6.60 & <1e-10 & 0.2542 \\\\\n",
       "f1 & -0.0123 & 0.0126 & -0.97 & 0.3296 & 0.1341 \\\\\n",
       "f2 & -0.0058 & 0.0095 & -0.61 & 0.5440 & 0.1035 \\\\\n",
       "f3 & 0.0245 & 0.0124 & 1.97 & 0.0485 & 0.0922 \\\\\n",
       "iqZ & -0.0022 & 0.0092 & -0.25 & 0.8060 & 0.0942 \\\\\n",
       "valence \\& f1 & -0.0119 & 0.0176 & -0.68 & 0.4992 & 0.0700 \\\\\n",
       "valence \\& f2 & -0.0039 & 0.0144 & -0.27 & 0.7855 & 0.0670 \\\\\n",
       "valence \\& f3 & 0.0464 & 0.0180 & 2.57 & 0.0101 & 0.0518 \\\\\n",
       "valence \\& iqZ & 0.0313 & 0.0189 & 1.65 & 0.0987 & 0.1564 \\\\\n",
       "Residual & 0.0017 &  &  &  &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "|               |    Est. |     SE |     z |      p |  σ_sub |\n",
       "|:------------- | -------:| ------:| -----:| ------:| ------:|\n",
       "| (Intercept)   |  0.1304 | 0.0091 | 14.36 | <1e-46 | 0.1091 |\n",
       "| valence       |  0.1058 | 0.0160 |  6.60 | <1e-10 | 0.2542 |\n",
       "| f1            | -0.0123 | 0.0126 | -0.97 | 0.3296 | 0.1341 |\n",
       "| f2            | -0.0058 | 0.0095 | -0.61 | 0.5440 | 0.1035 |\n",
       "| f3            |  0.0245 | 0.0124 |  1.97 | 0.0485 | 0.0922 |\n",
       "| iqZ           | -0.0022 | 0.0092 | -0.25 | 0.8060 | 0.0942 |\n",
       "| valence & f1  | -0.0119 | 0.0176 | -0.68 | 0.4992 | 0.0700 |\n",
       "| valence & f2  | -0.0039 | 0.0144 | -0.27 | 0.7855 | 0.0670 |\n",
       "| valence & f3  |  0.0464 | 0.0180 |  2.57 | 0.0101 | 0.0518 |\n",
       "| valence & iqZ |  0.0313 | 0.0189 |  1.65 | 0.0987 | 0.1564 |\n",
       "| Residual      |  0.0017 |        |       |        |        |\n"
      ],
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       " w ~ 1 + valence + f1 + f2 + f3 + iqZ + valence & f1 + valence & f2 + valence & f3 + valence & iqZ + (1 + valence + f1 + f2 + f3 + iqZ + valence & f1 + valence & f2 + valence & f3 + valence & iqZ | sub)\n",
       "   logLik   -2 logLik     AIC       AICc        BIC    \n",
       "   104.8600  -209.7199   -77.7199   -62.8560   218.9676\n",
       "\n",
       "Variance components:\n",
       "             Column     Variance  Std.Dev.   Corr.\n",
       "sub      (Intercept)    0.0119045 0.1091076\n",
       "         valence        0.0646176 0.2541999 -0.84\n",
       "         f1             0.0179924 0.1341358 -0.12 +0.18\n",
       "         f2             0.0107019 0.1034501 -0.07 -0.05 -0.94\n",
       "         f3             0.0085007 0.0921995 +0.20 -0.26 -0.35 +0.07\n",
       "         iqZ            0.0088759 0.0942121 +0.46 +0.02 +0.48 -0.54 -0.37\n",
       "         valence & f1   0.0048975 0.0699822 -0.01 -0.48 -0.10 +0.25 -0.20 -0.59\n",
       "         valence & f2   0.0044833 0.0669573 +0.24 -0.15 +0.65 -0.85 +0.45 +0.32 -0.33\n",
       "         valence & f3   0.0026816 0.0517842 -0.21 +0.67 +0.17 -0.10 -0.50 +0.66 -0.73 -0.16\n",
       "         valence & iqZ  0.0244571 0.1563878 -0.65 +0.14 +0.10 +0.08 -0.07 -0.79 +0.71 -0.15 -0.55\n",
       "Residual                0.0000028 0.0016865\n",
       " Number of obs: 662; levels of grouping factors: 331\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "───────────────────────────────────────────────────────\n",
       "                     Coef.  Std. Error      z  Pr(>|z|)\n",
       "───────────────────────────────────────────────────────\n",
       "(Intercept)     0.130404    0.00908332  14.36    <1e-46\n",
       "valence         0.105807    0.016023     6.60    <1e-10\n",
       "f1             -0.012274    0.012589    -0.97    0.3296\n",
       "f2             -0.00579106  0.00954333  -0.61    0.5440\n",
       "f3              0.0244737   0.0124022    1.97    0.0485\n",
       "iqZ            -0.00224826  0.00915397  -0.25    0.8060\n",
       "valence & f1   -0.011865    0.0175581   -0.68    0.4992\n",
       "valence & f2   -0.00393162  0.0144466   -0.27    0.7855\n",
       "valence & f3    0.0463536   0.0180249    2.57    0.0101\n",
       "valence & iqZ   0.0312767   0.0189444    1.65    0.0987\n",
       "───────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# supp table 7 & 9: compare w+ to w- (interaction with lsas / f3 is signif in Exp 2)\n",
    "# using mixed model to capture repeated measures by subject\n",
    "# note that Julia's MixedModels, unlike Matlab, doesnt use Satterthwaite DOF\n",
    "# but this difference is minimal for this many subjects\n",
    "\n",
    "exp2ws = DataFrame(w = [exp2covars.wplus;exp2covars.wminus], \n",
    "    sub = categorical([exp2subs;exp2subs]), \n",
    "    iqZ = [exp2covars.iqZ; exp2covars.iqZ], \n",
    "    lsasZ = [exp2covars.lsasZ; exp2covars.lsasZ], \n",
    "    f1 = [exp2covars.f1; exp2covars.f1], \n",
    "    f2 = [exp2covars.f2; exp2covars.f2], \n",
    "    f3 = [exp2covars.f3; exp2covars.f3], \n",
    "    valence = [ones(size(exp2subs));zeros(size(exp2subs))]\n",
    ")\n",
    "\n",
    "# supp tabel 7\n",
    "\n",
    "mm = (fit(MixedModel, @formula(w ~ 1 + valence * (lsasZ + iqZ) + (1 + valence * (lsasZ + iqZ) |sub)), exp2ws))\n",
    "display(mm)\n",
    "\n",
    "# supp table 9\n",
    "\n",
    "mm2 = (fit(MixedModel, @formula(w ~ 1 + valence * (f1 + f2 + f3 + iqZ) + (1 + valence * (f1 + f2 + f3 + iqZ) |sub)), exp2ws))\n",
    "display(mm2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
